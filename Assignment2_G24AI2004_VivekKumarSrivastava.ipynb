{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV7B2Z4ijt176Qei679Zva",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viks-iitj/Assignment2-G24AI2004-VivekKumarSrivastava/blob/main/Assignment2_G24AI2004_VivekKumarSrivastava.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indian Institute of Technology Jodhpur\n",
        "##Fundamentals of Distributed Systems\n",
        "\n",
        "###Assignment – 2\n",
        "\n",
        "Total Marks: 20, Submission Deadline: 27 July 2025\n",
        "\n",
        "###Submitted by : Vivek Kumar Srivastava (Roll- G24AI2004)\n",
        "Colab Link (Read Only):\n",
        "https://colab.research.google.com/drive/\n",
        "1mQ_iLOlu29iC3M96XPHEBk7S6xo7tWGn?usp=sharing\n",
        "\n",
        "Github Link : https://github.com/viks-iitj/Assignment2-G24AI2004-\n",
        "VivekKumarSrivastava.git\n",
        "\n",
        "Colab (Editable), you can get it from Github by click on “Open in Colab icon” to\n",
        "execute the project:\n",
        "https://colab.research.google.com/github/viks-iitj/Assignment2-G24AI2004-\n",
        "VivekKumarSrivastava/blob/main/\n",
        "Assignment2_G24AI2004_VivekKumarSrivastava.ipynb"
      ],
      "metadata": {
        "id": "LxVNaU5opKbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##=============================================================================="
      ],
      "metadata": {
        "id": "2FSCfh5gSXdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment : Installing necessary dependencies\n",
        "\n",
        "*   mrjob\n",
        "*   Hadoop\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1A9mXgSiLxqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQyfCOeAKzpl",
        "outputId": "3312e772-be1c-4327-86bf-4eb9cb8145a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from mrjob) (6.0.2)\n",
            "Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq0KEAREM_E3",
        "outputId": "18ee5353-42e0-44fb-8a99-f0b80dc4cf48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 17:01:23--  https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.208.237, 2a01:4f8:10a:39da::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 730107476 (696M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.6.tar.gz.1’\n",
            "\n",
            "hadoop-3.3.6.tar.gz 100%[===================>] 696.28M  23.1MB/s    in 32s     \n",
            "\n",
            "2025-07-28 17:01:55 (22.0 MB/s) - ‘hadoop-3.3.6.tar.gz.1’ saved [730107476/730107476]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf hadoop-3.3.6.tar.gz"
      ],
      "metadata": {
        "id": "-v6sOQ3YNxQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv hadoop-3.3.6 /usr/local/hadoop"
      ],
      "metadata": {
        "id": "HCNzA7kmOCIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##=============================================================================="
      ],
      "metadata": {
        "id": "TiLHDpmapCWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Cruiseline Aggregations (5 marks) :\n",
        "Using cruise.csv, implement an mrjob class that computes, for each Cruise line:\n",
        "\n",
        "(a) Total number of ships.\n",
        "\n",
        "(b) Average Tonnage (to two decimals).\n",
        "\n",
        "(c) Maximum crew size.\n",
        "\n",
        "(Optional) Use a Combiner for partial aggregation."
      ],
      "metadata": {
        "id": "2UMFbbhJpCla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.   Load full Data Set :\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ORY5HGUROT4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ItusAcOfdX",
        "outputId": "314139e0-56f1-4044-cf40-ab43890b8359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 17:07:49--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8734 (8.5K) [text/plain]\n",
            "Saving to: ‘cruise.csv’\n",
            "\n",
            "\rcruise.csv            0%[                    ]       0  --.-KB/s               \rcruise.csv          100%[===================>]   8.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-07-28 17:07:49 (77.6 MB/s) - ‘cruise.csv’ saved [8734/8734]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.   Create Sample data from the downloaded file :"
      ],
      "metadata": {
        "id": "MhjxW9U3NfUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Read the cruise.csv file\n",
        "rows = []\n",
        "with open(\"cruise.csv\", newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Choose random 10 samples\n",
        "sampled_rows = random.sample(rows, 10)\n",
        "\n",
        "# Save to sample_cruise.csv\n",
        "with open(\"sample_cruise.csv\", \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(sampled_rows)\n"
      ],
      "metadata": {
        "id": "mvMhVUBGNt7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat sample_cruise.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw1Xf-llia3N",
        "outputId": "1557c2b2-cf74-44d2-e755-65d304a4f343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ship_name,Cruise_line,Age,Tonnage,passengers,length,cabins,passenger_density,crew\r\n",
            "Grand,Princess,15,108.806,26.0,9.51,13.0,41.85,11.1\r\n",
            "Adventure,Royal_Caribbean,12,138.0,31.14,10.2,15.57,44.32,11.85\r\n",
            "Victory,Carnival,13,101.509,27.58,8.93,13.79,36.81,11.5\r\n",
            "Oriana,P&O,18,69.153,18.82,8.53,9.14,36.74,7.94\r\n",
            "Dawn,Norwegian,11,90.0,22.4,9.65,11.2,40.18,11.0\r\n",
            "Inspiration,Carnival,17,70.367,20.52,8.55,10.2,34.29,9.2\r\n",
            "Musica,MSC,7,89.6,25.5,9.61,12.75,35.14,9.87\r\n",
            "Constellation,Celebrity,11,91.0,20.32,9.65,9.75,44.78,9.99\r\n",
            "Saphire,Princess,9,113.0,26.74,9.51,13.37,42.26,12.38\r\n",
            "Oosterdam,Holland_American,10,81.76899999999999,18.48,9.59,9.24,44.25,8.42\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create mrjob class :"
      ],
      "metadata": {
        "id": "B0JZeyTwPTuc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09b2d7f0",
        "outputId": "422e4512-93cd-4aca-bc25-94f65fcfc675"
      },
      "source": [
        "%%writefile cruise_stats.py\n",
        "# -----------------------------------------------------------------------------\n",
        "# Author: Vivek Srivastava\n",
        "# Date: 2025-07-26\n",
        "# Description: MRJob script to calculate for each cruise line:\n",
        "#              - Total number of ships\n",
        "#              - Average tonnage (rounded to 2 decimals)\n",
        "#              - Maximum crew size\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "import io\n",
        "\n",
        "class CruiseLineStats(MRJob):\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Mapper: Parses each line and emits (cruise_line, (1, tonnage, crew))\n",
        "    # ------------------------------------------------------------\n",
        "    def mapper(self, _, line):\n",
        "        try:\n",
        "            if isinstance(line, bytes):\n",
        "                line = line.decode('utf-8')\n",
        "\n",
        "            row = next(csv.reader(io.StringIO(line)))\n",
        "\n",
        "            if row[0].strip().lower() == \"ship_name\":\n",
        "                return\n",
        "\n",
        "            cruise_line = row[1].strip()\n",
        "            tonnage = float(row[3].strip())\n",
        "            crew = float(row[8].strip())\n",
        "\n",
        "            yield cruise_line, (1, tonnage, crew)\n",
        "\n",
        "        except:\n",
        "            return\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Combiner: Partially aggregates count, total tonnage, and max crew per cruise line\n",
        "    # ------------------------------------------------------------\n",
        "    def combiner(self, cruise_line, values):\n",
        "        count, total_tonnage, max_crew = 0, 0.0, 0.0\n",
        "        for c, t, cr in values:\n",
        "            count += c\n",
        "            total_tonnage += t\n",
        "            max_crew = max(max_crew, cr)\n",
        "        yield cruise_line, (count, total_tonnage, max_crew)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Reducer: Final aggregation and formatting output for each cruise line\n",
        "    # ------------------------------------------------------------\n",
        "    def reducer(self, cruise_line, values):\n",
        "        count, total_tonnage, max_crew = 0, 0.0, 0.0\n",
        "        for c, t, cr in values:\n",
        "            count += c\n",
        "            total_tonnage += t\n",
        "            max_crew = max(max_crew, cr)\n",
        "\n",
        "        if count > 0:\n",
        "            avg_tonnage = round(total_tonnage / count, 2)\n",
        "            result = f\"{cruise_line:<25}{count:>6}{avg_tonnage:>15}{max_crew:>12}\"\n",
        "            yield None, result\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Define MapReduce steps using MRStep API\n",
        "    # ------------------------------------------------------------\n",
        "    def steps(self):\n",
        "        return [MRStep(mapper=self.mapper,\n",
        "                       combiner=self.combiner,\n",
        "                       reducer=self.reducer)]\n",
        "\n",
        "# Run the job\n",
        "if __name__ == '__main__':\n",
        "    CruiseLineStats.run()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cruise_stats.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Run Script on Sample Data :"
      ],
      "metadata": {
        "id": "eB8y72NTtmfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 cruise_stats.py sample_cruise.csv > sample_cruise.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssF8LMFHKvq",
        "outputId": "4f6e98fb-1d97-4900-ec2c-15e106ee05e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/cruise_stats.root.20250728.170227.437696\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/cruise_stats.root.20250728.170227.437696/output\n",
            "Streaming final output from /tmp/cruise_stats.root.20250728.170227.437696/output...\n",
            "Removing temp directory /tmp/cruise_stats.root.20250728.170227.437696...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Display Sample Test Result :"
      ],
      "metadata": {
        "id": "U62mXceNtvln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the header once\n",
        "print(f\"{'Cruise Line':<25}{'Ships':>6}{'Avg Tonnage':>15}{'Max Crew':>12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Read and clean output lines from the file\n",
        "with open(\"sample_cruise.txt\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if \"\\t\" in line:\n",
        "            _, value = line.split(\"\\t\", 1)\n",
        "            print(value.strip('\"'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydGxvzNQHR3D",
        "outputId": "0bdbb632-a733-4f20-ccea-af4535af7cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cruise Line               Ships    Avg Tonnage    Max Crew\n",
            "------------------------------------------------------------\n",
            "MSC                           1           89.6        9.87\n",
            "Norwegian                     1           90.0        11.0\n",
            "P&O                           1          69.15        7.94\n",
            "Princess                      2          110.9       12.38\n",
            "Royal_Caribbean               1          138.0       11.85\n",
            "Carnival                      2          85.94        11.5\n",
            "Celebrity                     1           91.0        9.99\n",
            "Holland_American              1          81.77        8.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Run Scripton on Full Dataset :"
      ],
      "metadata": {
        "id": "0QyeF9SYRf5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 cruise_stats.py cruise.csv > cruise.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmTcugO8RX55",
        "outputId": "301c6f7b-37a9-46b9-93e6-0b1a696dd948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/cruise_stats.root.20250728.170228.101517\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/cruise_stats.root.20250728.170228.101517/output\n",
            "Streaming final output from /tmp/cruise_stats.root.20250728.170228.101517/output...\n",
            "Removing temp directory /tmp/cruise_stats.root.20250728.170228.101517...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Display Result for Full Data Set (Final Output) :"
      ],
      "metadata": {
        "id": "_xw6k3d6btOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the header once\n",
        "print(f\"{'Cruise Line':<25}{'Ships':>6}{'Avg Tonnage':>15}{'Max Crew':>12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Read and clean output lines from the file\n",
        "with open(\"cruise.txt\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if \"\\t\" in line:\n",
        "            _, value = line.split(\"\\t\", 1)\n",
        "            print(value.strip('\"'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PSGjI0tbvoA",
        "outputId": "906e1b34-3564-40d8-9703-d7fb9a47f304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cruise Line               Ships    Avg Tonnage    Max Crew\n",
            "------------------------------------------------------------\n",
            "Cunard                        3         103.91       12.53\n",
            "Disney                        2          83.17        9.45\n",
            "Holland_American             14           60.5        8.42\n",
            "MSC                           8          63.77       13.13\n",
            "Norwegian                    13          63.72        13.0\n",
            "Oceania                       3          30.28         4.0\n",
            "Orient                        1          22.08         3.5\n",
            "P&O                           6          77.86        12.2\n",
            "Princess                     17          87.54       12.38\n",
            "Regent_Seven_Seas             5          32.14        4.47\n",
            "Royal_Caribbean              23         107.01        21.0\n",
            "Azamara                       2          30.28        3.55\n",
            "Carnival                     22          84.65        19.1\n",
            "Celebrity                    10          76.16        9.99\n",
            "Costa                        11           71.1        10.9\n",
            "Crystal                       2           59.5        6.36\n",
            "Seabourn                      3           10.0         1.6\n",
            "Silversea                     4           20.9        2.95\n",
            "Star                          6          30.77        12.0\n",
            "Windstar                      3           8.48         1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##=============================================================================="
      ],
      "metadata": {
        "id": "U7BvTdtESIFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Company Churn Rate (5 marks)\n",
        "From customer churn.csv, create a MultiStepJob:\n",
        "\n",
        "Step 1: Mapper emits (Company, TOTAL) and (Company, CHURNED) where Churn==1.\n",
        "\n",
        "Step 2: Reducer computes churn rate=CHURNED/TOTAL , outputting four-decimal floats.\n",
        "\n",
        "Use a small VIP companies.txt in the distributed cache to restrict to listed companies.\n",
        "Provide a sample file with at least three names."
      ],
      "metadata": {
        "id": "ed95fF5XdOdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.   Load full Data Set :"
      ],
      "metadata": {
        "id": "YZtBdjj_d65m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/customer_churn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8GWX6OCQJrI",
        "outputId": "2c3eb95e-e673-4bd6-f09b-dc9cd7f53303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 17:08:46--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/customer_churn.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 115479 (113K) [text/plain]\n",
            "Saving to: ‘customer_churn.csv’\n",
            "\n",
            "\rcustomer_churn.csv    0%[                    ]       0  --.-KB/s               \rcustomer_churn.csv  100%[===================>] 112.77K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-07-28 17:08:47 (4.53 MB/s) - ‘customer_churn.csv’ saved [115479/115479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Sample data from the downloaded file :"
      ],
      "metadata": {
        "id": "DTCQ1v4ZuvCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Read the customer_churn.csv file\n",
        "rows = []\n",
        "with open(\"customer_churn.csv\", newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Choose random 10 samples\n",
        "sampled_rows = random.sample(rows, 10)\n",
        "\n",
        "# Save to sample_customer_churn.csv\n",
        "with open(\"sample_customer_churn.csv\", \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(sampled_rows)"
      ],
      "metadata": {
        "id": "LCOJTDmCUofP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat sample_customer_churn.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGrLSiA8iUXh",
        "outputId": "61512bda-f698-4618-d6d4-10eef8cc53ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names,Age,Total_Purchase,Account_Manager,Years,Num_Sites,Onboard_date,Location,Company,Churn\r\n",
            "Lawrence Gordon,44.0,8817.22,1,6.53,10.0,2009-09-23 09:35:38,\"4041 Wise River Suite 828 West Todd, AR 08725-4767\",\"Austin, Roberts and Cox\",0\r\n",
            "Meghan Jackson,46.0,9844.79,0,3.57,11.0,2010-01-03 10:44:43,\"6574 Travis Extensions New Casey, RI 40982\",Phillips-Peters,0\r\n",
            "Kenneth Wilkerson,42.0,11670.32,0,5.51,7.0,2014-05-08 21:37:57,Unit 8005 Box 5636 DPO AA 90315-7695,\"Aguilar, Kelly and Fuentes\",0\r\n",
            "Daniel Barton,44.0,9855.18,0,6.94,7.0,2011-06-10 20:04:28,\"551 Davis Crescent New Aliciaport, TX 94552-1600\",Davidson Group,0\r\n",
            "Cheryl Bruce,44.0,9613.84,1,4.38,8.0,2014-06-18 19:25:33,\"PSC 5054, Box 2004 APO AP 20629\",\"Oconnor, Hernandez and Bailey\",0\r\n",
            "Laura Turner,42.0,8934.99,1,6.21,8.0,2010-10-26 19:01:20,\"46278 Austin Views Apt. 675 Port Paulfurt, KS 08809-6244\",\"Johnson, Myers and Martinez\",0\r\n",
            "Devin Wilson,46.0,11222.48,0,4.92,9.0,2011-02-18 18:11:37,\"97426 Carrie Stravenue East Cassandrafort, WV 23196\",Cooke Ltd,1\r\n",
            "Dakota Porter,41.0,7683.97,1,6.17,7.0,2007-08-23 19:38:19,\"1005 Butler Manors Richardland, KS 45645-6252\",Nguyen PLC,0\r\n",
            "Phillip White,42.0,8010.76,0,6.71,10.0,2014-04-22 12:43:12,\"13120 Daniel Mount Angelabury, WY 30645-4695\",Smith Inc,1\r\n",
            "Aaron Meyer,45.0,9598.03,0,5.0,7.0,2010-07-17 03:30:38,\"35821 Bailey Skyway Alexisstad, NH 81472\",\"Steele, Bates and Lane\",0\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Creating VIP_companies text file :"
      ],
      "metadata": {
        "id": "SnJN7l8MudVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile VIP_companies.txt\n",
        "Cooke Ltd\n",
        "Reynolds-Sheppard\n",
        "Austin Ltd\n",
        "Smith Inc\n",
        "Phillips-Peters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBJVQB0LKMt",
        "outputId": "7a40b8c8-ed68-461a-b95e-baaee5b65b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting VIP_companies.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create mrjob class :\n",
        "class with a MultiStepJob to calculate the churn rate for each company, using the distributed cache to filter for VIP companies."
      ],
      "metadata": {
        "id": "jgzltR9tegod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile churn_rate.py\n",
        "# -----------------------------------------------------------------------------\n",
        "# Author: Vivek Srivastava\n",
        "# Date: 2025-07-26\n",
        "# Description: MRJob script to compute churn rate per company using a two-step\n",
        "#              process restricted to VIP companies listed in a side file.\n",
        "#              Output: Company → Churn Rate (4 decimal places)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "import io\n",
        "\n",
        "class CompanyChurnRate(MRJob):\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Configure command-line argument to accept VIP file\n",
        "    # ------------------------------------------------------------\n",
        "    def configure_args(self):\n",
        "        super().configure_args()\n",
        "        self.add_file_arg('--vipfile', help='Path to VIP companies file')\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Mapper Init: Load VIP companies from file into a set\n",
        "    # ------------------------------------------------------------\n",
        "    def mapper_init(self):\n",
        "        self.vip_companies = set()\n",
        "        if self.options.vipfile:\n",
        "            with open(self.options.vipfile, 'r') as f:\n",
        "                self.vip_companies = {line.strip() for line in f}\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Mapper: Emits (company, 'TOTAL') and (company, 'CHURNED')\n",
        "    # for VIP companies only, based on churn flag\n",
        "    # ------------------------------------------------------------\n",
        "    def mapper(self, _, line):\n",
        "        try:\n",
        "            row = next(csv.reader([line], delimiter=\",\"))\n",
        "\n",
        "            # Skip header row\n",
        "            if row[0].strip().lower() == \"names\":\n",
        "                return\n",
        "\n",
        "            company = row[8].strip().strip('\"')\n",
        "            churn = row[9].strip()\n",
        "\n",
        "            if company in self.vip_companies:\n",
        "                yield company, \"TOTAL\"\n",
        "                if churn == \"1\":\n",
        "                    yield company, \"CHURNED\"\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Reducer: Calculates churn rate = CHURNED / TOTAL\n",
        "    # ------------------------------------------------------------\n",
        "    def reducer(self, company, values):\n",
        "        total = churned = 0\n",
        "        for v in values:\n",
        "            if v == \"TOTAL\":\n",
        "                total += 1\n",
        "            elif v == \"CHURNED\":\n",
        "                churned += 1\n",
        "\n",
        "        if total > 0:\n",
        "            churn_rate = churned / total\n",
        "            yield company, f\"{churn_rate:.4f}\"\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # MapReduce Steps API\n",
        "    # ------------------------------------------------------------\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(\n",
        "                mapper_init=self.mapper_init,\n",
        "                mapper=self.mapper,\n",
        "                reducer=self.reducer\n",
        "            )\n",
        "        ]\n",
        "\n",
        "# Run the job\n",
        "if __name__ == '__main__':\n",
        "    CompanyChurnRate.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxtmCyOGeogn",
        "outputId": "64e8df6e-b9c6-4c38-a427-d7a22bbbbadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting churn_rate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Run Script on Sample Data :"
      ],
      "metadata": {
        "id": "rPXeZAZ5ftoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 churn_rate.py sample_customer_churn.csv --vipfile VIP_companies.txt > sample_churn_output.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJW2qdcvLfhS",
        "outputId": "431b7e65-c54a-411e-b89c-fcea091a26da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/churn_rate.root.20250728.173834.250205\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/churn_rate.root.20250728.173834.250205/output\n",
            "Streaming final output from /tmp/churn_rate.root.20250728.173834.250205/output...\n",
            "Removing temp directory /tmp/churn_rate.root.20250728.173834.250205...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Display Sample Test Result :"
      ],
      "metadata": {
        "id": "2QTpUW4Vve3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Company':<30}{'Churn Rate':>12}\")\n",
        "print(\"-\" * 42)\n",
        "\n",
        "with open(\"sample_churn_output.txt\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        if len(parts) == 2:\n",
        "            company = parts[0].strip('\"')\n",
        "            rate = parts[1].strip()\n",
        "            print(f\"{company:<30}{rate:>12}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un1eiy1_LjXY",
        "outputId": "21f5476e-9af7-44dd-dd61-15472fc8ca0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company                         Churn Rate\n",
            "------------------------------------------\n",
            "Phillips-Peters                        0.0\n",
            "Smith Inc                              1.0\n",
            "Cooke Ltd                              1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Run Scripton on Full Dataset :"
      ],
      "metadata": {
        "id": "XmyllrZ_gRjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 churn_rate.py customer_churn.csv --vipfile VIP_companies.txt > customer_churn.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QpaR7KTgTCV",
        "outputId": "9dc4cc3b-888a-41e5-989c-487c20d24325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/churn_rate.root.20250728.173841.967681\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/churn_rate.root.20250728.173841.967681/output\n",
            "Streaming final output from /tmp/churn_rate.root.20250728.173841.967681/output...\n",
            "Removing temp directory /tmp/churn_rate.root.20250728.173841.967681...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Display Result for Full Data Set (Final Output) :"
      ],
      "metadata": {
        "id": "8IdJ7FEHg3Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Company':<30}{'Churn Rate':>12}\")\n",
        "print(\"-\" * 42)\n",
        "with open(\"customer_churn.txt\") as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split(\"\\t\")\n",
        "        if len(parts) == 2:\n",
        "            company = parts[0].strip('\"')\n",
        "            rate = parts[1].strip()\n",
        "            print(f\"{company:<30}{rate:>12}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBTIrpNvg5O4",
        "outputId": "b8632d98-539b-483f-f5d2-863abcf46ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company                         Churn Rate\n",
            "------------------------------------------\n",
            "Phillips-Peters                        0.0\n",
            "Reynolds-Sheppard                      1.0\n",
            "Smith Inc                              1.0\n",
            "Austin Ltd                             0.0\n",
            "Cooke Ltd                              1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##=============================================================================="
      ],
      "metadata": {
        "id": "NDo3h6OYW7n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. State-wise Spending (5 marks)\n",
        "From e-com customer.csv, extract the two-letter state code from the Address field.\n",
        "\n",
        "Then:\n",
        "\n",
        "• Mapper parses the state.\n",
        "\n",
        "• Reducer sums Yearly Amount Spent per state.\n",
        "\n",
        "• Output the top 5 states by total spending."
      ],
      "metadata": {
        "id": "lMaINttNEtFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load full Data Set :"
      ],
      "metadata": {
        "id": "HgtXUGlzW_l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/e-com_customer.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jCuK0v0XXo-",
        "outputId": "5af64ef2-5a45-4058-8792-b699636904ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 17:09:39--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/e-com_customer.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86871 (85K) [text/plain]\n",
            "Saving to: ‘e-com_customer.csv’\n",
            "\n",
            "\re-com_customer.csv    0%[                    ]       0  --.-KB/s               \re-com_customer.csv  100%[===================>]  84.83K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-07-28 17:09:40 (3.50 MB/s) - ‘e-com_customer.csv’ saved [86871/86871]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Sample data from the downloaded file :"
      ],
      "metadata": {
        "id": "cpkK0bPoFEqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Read the e-com_customer.csv file\n",
        "rows = []\n",
        "with open(\"e-com_customer.csv\", newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Choose random 10 samples\n",
        "sampled_rows = random.sample(rows, 10)\n",
        "\n",
        "# Save to sample_e-com_customer.csv\n",
        "with open(\"sample_e-com_customer.csv\", \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(sampled_rows)"
      ],
      "metadata": {
        "id": "FgWH72SjMWkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat sample_e-com_customer.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSMwVGMlnU4",
        "outputId": "d95baf74-8630-48a0-9da6-f52354f1723c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email,Address,Avatar,Avg Session Length,Time on App,Time on Website,Length of Membership,Yearly Amount Spent\r\n",
            "brian51@cook.info,\"0508 Terrance CliffRebekahtown, NC 48724-8308\",SaddleBrown,31.51712180250623,10.745188554182882,38.79123468689964,1.4288238768282668,275.9184206503857\r\n",
            "tracy79@wheeler.net,\"513 Moore Crescent Apt. 416Amandaberg, GU 03655-2219\",Magenta,32.2463499961189,11.305551430414742,37.133126759376324,1.7073897286757314,327.37795258965207\r\n",
            "esmith@gmail.com,USS JohnsonFPO AE 35617-5384,OldLace,34.18382052058911,13.349912944366533,37.827394227862136,4.252006105620936,614.7153338263417\r\n",
            "ethomas@yahoo.com,\"1279 Douglas MountainsPort Christopherberg, RI 32811-8325\",LightGreen,33.69489765096749,11.202669899735568,35.49396408005128,4.015986640445782,505.11963752820367\r\n",
            "morganorozco@hotmail.com,\"0001 Mack MillNorth Jennifer, NE 42021-5936\",LightPink,30.4925366965402,11.562936246652605,35.97656497174036,1.4816166268553612,282.4712457199145\r\n",
            "riverarebecca@gmail.com,\"1414 David ThroughwayPort Jason, OH 22070-1220\",SaddleBrown,34.30555662975554,13.717513665142507,36.72128267790313,3.120178782748092,581.8523440352177\r\n",
            "jenniferjenkins@jones.com,USNS JacobsFPO AE 71507-1312,LightSalmon,33.265444472845786,13.052210385161311,38.775665296116884,4.574287716419565,608.2718166151668\r\n",
            "victoria53@hotmail.com,\"16329 Sara Neck Apt. 463Bryanside, TX 62329\",Pink,32.63587799818993,12.178573080885847,35.6742560274292,4.131755039569861,537.7731625414566\r\n",
            "jimmy11@hardin.com,\"496 Bush Turnpike Apt. 674Donnabury, OR 32596-0079\",DarkGoldenRod,32.97518182625784,13.90991551102909,37.79223754313028,4.297686524285517,630.4227632299235\r\n",
            "jenniferking@hess.net,\"06939 Jones NeckMariaview, VT 87641\",BlueViolet,31.389585480664397,10.994223919350974,38.074452419704535,3.4288599039280125,410.0696110599829\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create mrjob class :"
      ],
      "metadata": {
        "id": "rQXmDcyFjtPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile top_states_spending.py\n",
        "# -----------------------------------------------------------------------------\n",
        "# Author: Vivek Srivastava\n",
        "# Date: 2025-07-27\n",
        "# Description: MRJob script to calculate top 5 U.S. states by total yearly\n",
        "#              customer spending from e-commerce data.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "import io\n",
        "\n",
        "class TopStatesSpending(MRJob):\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Mapper: Extracts the state code and spending amount.\n",
        "    # Emits: (state_code, yearly_amount_spent)\n",
        "    # ------------------------------------------------------------\n",
        "    def mapper(self, _, line):\n",
        "        try:\n",
        "            # Use csv.reader to handle quoted fields with commas\n",
        "            row = next(csv.reader(io.StringIO(line)))\n",
        "\n",
        "            # Skip header row\n",
        "            if row[0].strip().lower() == \"email\":\n",
        "                return\n",
        "\n",
        "            address = row[1].strip()\n",
        "            amount = float(row[7].strip())\n",
        "\n",
        "            # Extract the two-letter state code from the address\n",
        "            parts = address.split()\n",
        "            if len(parts) >= 2:\n",
        "                state = parts[-2].strip()\n",
        "                if len(state) == 2 and state.isalpha():\n",
        "                    yield state.upper(), amount\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Reducer: Sums all amounts spent for each state.\n",
        "    # Emits: (None, (total_amount, state))\n",
        "    # ------------------------------------------------------------\n",
        "    def reducer(self, state, amounts):\n",
        "        yield None, (sum(amounts), state)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Final Reducer: Sorts all (total, state) pairs and emits\n",
        "    # the top 5 states with the highest total spending.\n",
        "    # ------------------------------------------------------------\n",
        "    def reducer_top5(self, _, state_amounts):\n",
        "        top5 = sorted(state_amounts, reverse=True)[:5]\n",
        "        for total, state in top5:\n",
        "            yield state, round(total, 4)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Defines the MapReduce pipeline using MRStep API\n",
        "    # ------------------------------------------------------------\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper=self.mapper, reducer=self.reducer),\n",
        "            MRStep(reducer=self.reducer_top5)\n",
        "        ]\n",
        "\n",
        "# Run the job\n",
        "if __name__ == '__main__':\n",
        "    TopStatesSpending.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7qVpt3ijua1",
        "outputId": "8a835d40-d3f5-4e1e-904e-eb0fc22c82a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting top_states_spending.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Run Script on Sample Data :"
      ],
      "metadata": {
        "id": "lUwxNDEBkCCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 top_states_spending.py sample_e-com_customer.csv > sample_e-com_customer.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdEw1W43kEPu",
        "outputId": "d5017be0-a2ba-46b3-f614-8f3a07b500f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/top_states_spending.root.20250728.170230.648356\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/top_states_spending.root.20250728.170230.648356/output\n",
            "Streaming final output from /tmp/top_states_spending.root.20250728.170230.648356/output...\n",
            "Removing temp directory /tmp/top_states_spending.root.20250728.170230.648356...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Display Sample Test Result :"
      ],
      "metadata": {
        "id": "wf83Rs68m_U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'State':<10}{'Total Spending'}\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "with open(\"sample_e-com_customer.txt\") as f:\n",
        "    for line in f:\n",
        "        if \"\\t\" in line:\n",
        "            state, amount = line.strip().split(\"\\t\")\n",
        "            print(f\"{state:<10}{amount}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTRtHxNqmYW9",
        "outputId": "7443fe97-49f2-4295-972e-3ae05c725286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State     Total Spending\n",
            "------------------------------\n",
            "\"AE\"      1222.9872\n",
            "\"OR\"      630.4228\n",
            "\"OH\"      581.8523\n",
            "\"TX\"      537.7732\n",
            "\"RI\"      505.1196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Run Scripton on Full Dataset :"
      ],
      "metadata": {
        "id": "_nBt0lhGnCno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 top_states_spending.py e-com_customer.csv > e-com_customer.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcH2jwamnGxj",
        "outputId": "fbde2d19-10a5-45fa-d935-4d9d9aebf6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/top_states_spending.root.20250728.170231.077373\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in /tmp/top_states_spending.root.20250728.170231.077373/output\n",
            "Streaming final output from /tmp/top_states_spending.root.20250728.170231.077373/output...\n",
            "Removing temp directory /tmp/top_states_spending.root.20250728.170231.077373...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Display Result for Full Data Set (Final Output) :"
      ],
      "metadata": {
        "id": "nNK-dzYpnObY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'State':<10}{'Total Spending'}\")\n",
        "print(\"-\" * 30)\n",
        "with open(\"e-com_customer.txt\") as f:\n",
        "    for line in f:\n",
        "        if \"\\t\" in line:\n",
        "            state, amount = line.strip().split(\"\\t\")\n",
        "            print(f\"{state:<10}{amount}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM-uiWFhnSq8",
        "outputId": "8ad21cbb-bf45-4deb-a45d-4da7c2f0ce56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State     Total Spending\n",
            "------------------------------\n",
            "\"AE\"      8686.8303\n",
            "\"AA\"      8404.697\n",
            "\"SC\"      6820.2978\n",
            "\"DE\"      6644.9813\n",
            "\"MO\"      6402.5697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##=============================================================================="
      ],
      "metadata": {
        "id": "CteKRxBEYX0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Two-step Ship Filter & Median Length (5 marks)\n",
        "On cruise.csv, implement a two-step mrjob pipeline:\n",
        "\n",
        "Step 1: Filter ships with passenger density > 35.0; emit ⟨Cruise line, length⟩.\n",
        "\n",
        "Step 2: Compute the median of the lengths per Cruise line, handling even/odd counts correctly.\n",
        "\n",
        "Use the steps() API and output medians to two decimals."
      ],
      "metadata": {
        "id": "QXYsnsRCYk-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load full Data Set (creating duplicate as we have already added the data set as a part of Question1, will use the same data set for this question) :"
      ],
      "metadata": {
        "id": "fHpbj8V4Y144"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aqubuOuY6NS",
        "outputId": "5df52fe7-2381-4e0a-d50b-17e8f2a455e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-28 17:11:37--  https://raw.githubusercontent.com/TakMashhido/PGD-BigData-Tutorial/refs/heads/main/Dataset/cruise.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8734 (8.5K) [text/plain]\n",
            "Saving to: ‘cruise.csv.1’\n",
            "\n",
            "\rcruise.csv.1          0%[                    ]       0  --.-KB/s               \rcruise.csv.1        100%[===================>]   8.53K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-07-28 17:11:37 (14.8 MB/s) - ‘cruise.csv.1’ saved [8734/8734]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create Sample data from the downloaded file :"
      ],
      "metadata": {
        "id": "z_S8sngXZGc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Read the cruise.csv file\n",
        "rows = []\n",
        "with open(\"cruise.csv\", newline='') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    for row in reader:\n",
        "        rows.append(row)\n",
        "\n",
        "# Choose random 10 samples\n",
        "sampled_rows = random.sample(rows, 10)\n",
        "\n",
        "# Save to sample_cruise-1.csv\n",
        "with open(\"sample_cruise-1.csv\", \"w\", newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(sampled_rows)"
      ],
      "metadata": {
        "id": "8ik5Rp8AZIqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat sample_cruise-1.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfytQ8jhZgqx",
        "outputId": "8ea1317e-997f-4766-d70c-2a3c1b6aaae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ship_name,Cruise_line,Age,Tonnage,passengers,length,cabins,passenger_density,crew\r\n",
            "Spirit,Carnival,12,88.5,21.24,9.63,10.56,41.67,10.29\r\n",
            "Navigator,Regent_Seven_Seas,14,33.0,4.9,5.6,2.45,67.35,3.24\r\n",
            "Golden,Princess,12,108.865,27.58,9.51,13.0,39.47,11.0\r\n",
            "Solstice,Celebrity,5,122.0,28.5,10.33,6.87,34.57,6.7\r\n",
            "Rhapsody,Royal_Caribbean,16,78.491,24.35,9.15,10.0,32.23,7.65\r\n",
            "Summit,Celebrity,12,91.0,20.32,9.65,9.75,44.78,9.99\r\n",
            "Enchantment,Royal_Caribbean,16,74.137,19.5,9.16,9.75,38.02,7.6\r\n",
            "Monarch,Royal_Caribbean,22,73.941,27.44,8.8,11.77,30.94,8.22\r\n",
            "ExplorerII,Regent_Seven_Seas,27,12.5,3.94,4.36,0.88,31.73,1.46\r\n",
            "Sea,Norwegian,25,42.0,15.04,7.08,7.52,27.93,6.3\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create mrjob class :"
      ],
      "metadata": {
        "id": "xzF7Pt1IZ0ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cruise_median_length.py\n",
        "# -----------------------------------------------------------------------------\n",
        "# Author: Vivek Srivastava\n",
        "# Date: 2025-07-27\n",
        "# Description: MRJob script to compute median ship length per cruise line\n",
        "#              for ships with passenger density > 35.0\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import csv\n",
        "import io\n",
        "\n",
        "class CruiseMedianLength(MRJob):\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Step 1 Mapper: Filter ships with passenger_density > 35.0\n",
        "    # Emits: (Cruise_line, length)\n",
        "    # ------------------------------------------------------------\n",
        "    def mapper_filter_density(self, _, line):\n",
        "        try:\n",
        "            row = next(csv.reader(io.StringIO(line)))\n",
        "\n",
        "            # Skip header row\n",
        "            if row[0].strip().lower() == \"ship_name\":\n",
        "                return\n",
        "\n",
        "            cruise_line = row[1].strip()\n",
        "            length = float(row[5].strip())\n",
        "            density = float(row[7].strip())\n",
        "\n",
        "            if density > 35.0:\n",
        "                yield cruise_line, length\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Step 1 Reducer: Collect all lengths for each cruise line\n",
        "    # Computes the median of the lengths\n",
        "    # ------------------------------------------------------------\n",
        "    def reducer_group_lengths(self, cruise_line, lengths):\n",
        "        sorted_lengths = sorted(lengths)\n",
        "        n = len(sorted_lengths)\n",
        "\n",
        "        if n == 0:\n",
        "            return\n",
        "\n",
        "        # Compute median for odd or even number of ships\n",
        "        if n % 2 == 1:\n",
        "            median = sorted_lengths[n // 2]\n",
        "        else:\n",
        "            median = (sorted_lengths[n // 2 - 1] + sorted_lengths[n // 2]) / 2.0\n",
        "\n",
        "        # Emit cruise line with median length rounded to 2 decimals\n",
        "        yield cruise_line, round(median, 2)\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "    # Define MapReduce pipeline using MRStep\n",
        "    # ------------------------------------------------------------\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(\n",
        "                mapper=self.mapper_filter_density,\n",
        "                reducer=self.reducer_group_lengths\n",
        "            )\n",
        "        ]\n",
        "\n",
        "# Run the job\n",
        "if __name__ == '__main__':\n",
        "    CruiseMedianLength.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNOCSz7bZ3Gx",
        "outputId": "6aeae5c5-3c8f-4a96-9552-e30d73d9b3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cruise_median_length.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Run Script on Sample Data :"
      ],
      "metadata": {
        "id": "oEamrQJlaHXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 cruise_median_length.py sample_cruise-1.csv > sample_cruise-1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHUMyiwXaL7x",
        "outputId": "bdad0619-9797-4f08-fe69-08280f97aa08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/cruise_median_length.root.20250728.170231.744616\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/cruise_median_length.root.20250728.170231.744616/output\n",
            "Streaming final output from /tmp/cruise_median_length.root.20250728.170231.744616/output...\n",
            "Removing temp directory /tmp/cruise_median_length.root.20250728.170231.744616...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Display Sample Test Result :"
      ],
      "metadata": {
        "id": "_q4F082qaTwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Cruise Line':<25}{'Median Length'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "with open(\"sample_cruise-1.txt\") as f:\n",
        "    for line in f:\n",
        "        if \"\\t\" in line:\n",
        "            cruise_line, median = line.strip().split(\"\\t\")\n",
        "            print(f\"{cruise_line:<25}{median}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Zhi3h7aXIM",
        "outputId": "19d59f4f-799b-4b14-b325-c22dbda02a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cruise Line              Median Length\n",
            "----------------------------------------\n",
            "\"Princess\"               9.51\n",
            "\"Regent_Seven_Seas\"      5.6\n",
            "\"Royal_Caribbean\"        9.16\n",
            "\"Carnival\"               9.63\n",
            "\"Celebrity\"              9.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Run Scripton on Full Dataset :"
      ],
      "metadata": {
        "id": "XaVzwHRjahzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 cruise_median_length.py cruise.csv > cruise-1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js31XVXvauUQ",
        "outputId": "6d4329fe-5be5-470d-d7b2-20dd29d508ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/cruise_median_length.root.20250728.170232.168922\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/cruise_median_length.root.20250728.170232.168922/output\n",
            "Streaming final output from /tmp/cruise_median_length.root.20250728.170232.168922/output...\n",
            "Removing temp directory /tmp/cruise_median_length.root.20250728.170232.168922...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'Cruise Line':<25}{'Median Length'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "with open(\"cruise-1.txt\") as f:\n",
        "    for line in f:\n",
        "        if \"\\t\" in line:\n",
        "            cruise_line, median = line.strip().split(\"\\t\")\n",
        "            print(f\"{cruise_line:<25}{median}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvFgUAA_anMF",
        "outputId": "a4b4a575-e900-4cf6-ca7e-04ebfcaea33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cruise Line              Median Length\n",
            "----------------------------------------\n",
            "\"Disney\"                 9.64\n",
            "\"Holland_American\"       7.77\n",
            "\"MSC\"                    8.23\n",
            "\"Norwegian\"              9.0\n",
            "\"Oceania\"                5.94\n",
            "\"P&O\"                    8.56\n",
            "\"Princess\"               9.51\n",
            "\"Regent_Seven_Seas\"      6.15\n",
            "\"Royal_Caribbean\"        10.2\n",
            "\"Azamara\"                5.94\n",
            "\"Carnival\"               9.52\n",
            "\"Celebrity\"              9.65\n",
            "\"Costa\"                  8.28\n",
            "\"Crystal\"                7.86\n",
            "\"Cunard\"                 9.64\n",
            "\"Seabourn\"               4.4\n",
            "\"Silversea\"              5.55\n",
            "\"Star\"                   2.8\n",
            "\"Windstar\"               6.17\n"
          ]
        }
      ]
    }
  ]
}